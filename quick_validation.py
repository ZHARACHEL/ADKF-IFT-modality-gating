"""
å¿«é€ŸéªŒè¯é—¨æ§å’ŒAdapteræœ‰æ•ˆæ€§çš„è„šæœ¬
æ— éœ€å®Œæ•´è®­ç»ƒï¼Œç›´æ¥åˆ†æå·²è®­ç»ƒæ¨¡å‹çš„é—¨æ§è¡Œä¸º
"""
import torch
import numpy as np
import os
import sys
from collections import defaultdict

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, '.')

from fs_mol.utils.adaptive_dkt_utils import ADKTModelTrainer
from fs_mol.data import FSMolDataset, DataFold
from fs_mol.data.dkt import get_dkt_task_sample_iterable
from fs_mol.utils.torch_utils import torchify

def analyze_gate_weights(model_path, num_tasks=30):
    """åˆ†æé—¨æ§æƒé‡åœ¨ä¸åŒä»»åŠ¡ä¸Šçš„åˆ†å¸ƒ"""
    
    print("=" * 70)
    print("ğŸ” é—¨æ§æƒé‡åˆ†æ")
    print("=" * 70)
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"\nğŸ“± è®¾å¤‡: {device}")
    
    # åŠ è½½æ¨¡å‹
    print(f"ğŸ“‚ åŠ è½½æ¨¡å‹: {model_path}")
    model = ADKTModelTrainer.build_from_model_file(model_path, device=device)
    model = model.to(device)
    model.eval()
    
    # æ£€æŸ¥é…ç½®
    print(f"\nâš™ï¸ æ¨¡å‹é…ç½®:")
    print(f"   use_modality_gating: {model.config.use_modality_gating}")
    print(f"   use_statistics_adapter: {model.config.use_statistics_adapter}")
    print(f"   used_features: {model.config.used_features}")
    
    if not model.config.use_modality_gating:
        print("\nâŒ è¯¥æ¨¡å‹æœªå¯ç”¨é—¨æ§ï¼Œæ— æ³•åˆ†æé—¨æ§æƒé‡ï¼")
        return
    
    # åŠ è½½æ•°æ®é›†
    print(f"\nğŸ“Š åŠ è½½éªŒè¯é›†...")
    dataset = FSMolDataset.from_directory("./fs-mol-dataset")
    
    task_iter = iter(get_dkt_task_sample_iterable(
        dataset=dataset,
        data_fold=DataFold.VALIDATION,
        num_samples=1,
        max_num_graphs=64,
        support_size=16,
        query_size=32,
        repeat=False,
    ))
    
    # æ”¶é›†é—¨æ§æƒé‡
    gate_weights_by_modality = defaultdict(list)
    task_names = []
    
    print(f"\nğŸ”¬ åˆ†æ {num_tasks} ä¸ªä»»åŠ¡çš„é—¨æ§æƒé‡...")
    
    for i in range(num_tasks):
        try:
            task_sample = next(task_iter)
            task_sample = torchify(task_sample, device=device)
            batch = task_sample.batches[0]
            
            with torch.no_grad():
                _ = model(batch, train_loss=None)
            
            if hasattr(model, 'last_gate_weights') and model.last_gate_weights:
                task_names.append(task_sample.task_name)
                for modality, weight in model.last_gate_weights.items():
                    gate_weights_by_modality[modality].append(weight.item())
                
                if (i + 1) % 10 == 0:
                    print(f"   å·²å¤„ç† {i+1}/{num_tasks} ä¸ªä»»åŠ¡")
        except StopIteration:
            break
    
    # åˆ†æç»“æœ
    print("\n" + "=" * 70)
    print("ğŸ“Š é—¨æ§æƒé‡ç»Ÿè®¡åˆ†æ")
    print("=" * 70)
    
    for modality, weights in gate_weights_by_modality.items():
        weights = np.array(weights)
        print(f"\nã€{modality.upper()}ã€‘")
        print(f"   å‡å€¼: {weights.mean():.4f}")
        print(f"   æ ‡å‡†å·®: {weights.std():.4f}")
        print(f"   æœ€å°å€¼: {weights.min():.4f}")
        print(f"   æœ€å¤§å€¼: {weights.max():.4f}")
        print(f"   èŒƒå›´: {weights.max() - weights.min():.4f}")
    
    # åˆ¤æ–­é—¨æ§æ˜¯å¦æœ‰æ•ˆ
    print("\n" + "=" * 70)
    print("ğŸ¯ æœ‰æ•ˆæ€§åˆ¤æ–­")
    print("=" * 70)
    
    all_stds = [np.array(w).std() for w in gate_weights_by_modality.values()]
    avg_std = np.mean(all_stds)
    
    all_ranges = [np.array(w).max() - np.array(w).min() for w in gate_weights_by_modality.values()]
    avg_range = np.mean(all_ranges)
    
    print(f"\n   å¹³å‡æ ‡å‡†å·®: {avg_std:.4f}")
    print(f"   å¹³å‡èŒƒå›´: {avg_range:.4f}")
    
    if avg_std < 0.05:
        print("\n   âš ï¸ é—¨æ§æƒé‡å˜åŒ–å¾ˆå°ï¼ˆstd < 0.05ï¼‰")
        print("   â†’ é—¨æ§å¯èƒ½æ²¡æœ‰å­¦åˆ°æœ‰æ„ä¹‰çš„æ¨¡æ€é€‰æ‹©")
        print("   â†’ å»ºè®®ï¼šå¢åŠ è®­ç»ƒæ­¥æ•°æˆ–è°ƒæ•´é—¨æ§ç½‘ç»œç»“æ„")
    elif avg_std < 0.1:
        print("\n   ğŸ“Š é—¨æ§æƒé‡æœ‰ä¸€å®šå˜åŒ–ï¼ˆ0.05 < std < 0.1ï¼‰")
        print("   â†’ é—¨æ§æ­£åœ¨å­¦ä¹ ï¼Œä½†æ•ˆæœå¯èƒ½ä¸å¤Ÿæ˜æ˜¾")
    else:
        print("\n   âœ… é—¨æ§æƒé‡å˜åŒ–æ˜æ˜¾ï¼ˆstd > 0.1ï¼‰")
        print("   â†’ é—¨æ§æ­£åœ¨æ ¹æ®ä»»åŠ¡ç‰¹æ€§è°ƒæ•´æ¨¡æ€æƒé‡")
    
    # æ£€æŸ¥æ¨¡æ€é—´å·®å¼‚
    if len(gate_weights_by_modality) > 1:
        modalities = list(gate_weights_by_modality.keys())
        means = [np.array(gate_weights_by_modality[m]).mean() for m in modalities]
        max_diff = max(means) - min(means)
        
        print(f"\n   æ¨¡æ€é—´å‡å€¼å·®å¼‚: {max_diff:.4f}")
        if max_diff > 0.1:
            print("   âœ… ä¸åŒæ¨¡æ€æœ‰ä¸åŒçš„å¹³å‡æƒé‡")
        else:
            print("   âš ï¸ æ‰€æœ‰æ¨¡æ€æƒé‡ç›¸ä¼¼ï¼Œé—¨æ§å¯èƒ½æ²¡æœ‰å­¦åˆ°åŒºåˆ†")
    
    return gate_weights_by_modality, task_names


def quick_ablation_check():
    """å¿«é€Ÿå¯¹æ¯”ä¸åŒé…ç½®çš„æ¨¡å‹"""
    
    print("\n" + "=" * 70)
    print("ğŸ§ª å¿«é€Ÿæ¶ˆèåˆ†æ")
    print("=" * 70)
    
    outputs_dir = "./outputs"
    models_found = []
    
    for folder in os.listdir(outputs_dir):
        model_path = os.path.join(outputs_dir, folder, "best_validation.pt")
        if os.path.exists(model_path):
            try:
                checkpoint = torch.load(model_path, map_location='cpu')
                config = checkpoint.get('model_config')
                if config:
                    models_found.append({
                        'folder': folder,
                        'path': model_path,
                        'gating': getattr(config, 'use_modality_gating', 'Unknown'),
                        'adapter': getattr(config, 'use_statistics_adapter', 'Unknown'),
                    })
            except:
                pass
    
    print(f"\næ‰¾åˆ° {len(models_found)} ä¸ªæ¨¡å‹:")
    for m in models_found[-5:]:  # æ˜¾ç¤ºæœ€è¿‘5ä¸ª
        print(f"   ğŸ“ {m['folder']}")
        print(f"      Gate: {m['gating']}, Adapter: {m['adapter']}")
    
    return models_found


if __name__ == "__main__":
    # 1. æŸ¥æ‰¾æœ€æ–°æ¨¡å‹
    print("ğŸ” æŸ¥æ‰¾æœ€æ–°è®­ç»ƒçš„æ¨¡å‹...")
    outputs = sorted([d for d in os.listdir("outputs") if d.startswith("FSMol_ADKTModel")])
    
    if outputs:
        latest = outputs[-1]
        model_path = f"outputs/{latest}/best_validation.pt"
        
        if os.path.exists(model_path):
            print(f"ğŸ“‚ ä½¿ç”¨æ¨¡å‹: {latest}")
            
            # åˆ†æé—¨æ§æƒé‡
            gate_weights, task_names = analyze_gate_weights(model_path, num_tasks=30)
            
            # å¿«é€Ÿæ¶ˆèæ£€æŸ¥
            quick_ablation_check()
        else:
            print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
    else:
        print("âŒ æœªæ‰¾åˆ°è®­ç»ƒè¾“å‡ºç›®å½•")
